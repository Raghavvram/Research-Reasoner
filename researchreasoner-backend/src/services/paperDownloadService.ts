
import fs from 'fs';
import path from 'path';
import axios from 'axios';
import { promisify } from 'util';
import { pipeline } from 'stream';
import neo4jService from './neo4jService';

const streamPipeline = promisify(pipeline);

export interface DownloadProgress {
  paperId: string;
  title: string;
  status: 'pending' | 'downloading' | 'completed' | 'failed';
  progress: number;
  error?: string;
  filePath?: string | null;
  fileSize?: number;
  storedInDatabase?: boolean;
  contentType?: string;
  downloadStrategy?: string;
}

export interface BulkDownloadResult {
  sessionId: string;
  totalPapers: number;
  completed: number;
  failed: number;
  totalSize: number;
  downloadPaths: string[];
  progress: DownloadProgress[];
  databaseStorageComplete?: boolean;
  pdfDownloaded?: number;
  textCreated?: number;
}

export class PaperDownloadService {
  private downloadDir: string;
  private maxConcurrentDownloads = 3;
  private activeDownloads = new Map<string, BulkDownloadResult>();

  constructor() {
    this.downloadDir = path.join(process.cwd(), 'downloads');
    this.ensureDirectoryExists(this.downloadDir);
    
    // Create topic-based subdirectories
    ['machine_learning', 'artificial_intelligence', 'computer_science', 'quantum_computing', 'climate_change', 'general'].forEach(topic => {
      this.ensureDirectoryExists(path.join(this.downloadDir, topic));
    });
    
    console.log(`üìÅ PDF Download service initialized: ${this.downloadDir}`);
  }

  private ensureDirectoryExists(dirPath: string): void {
    if (!fs.existsSync(dirPath)) {
      fs.mkdirSync(dirPath, { recursive: true });
    }
  }

  
  private async downloadSinglePaperPDF(paper: any, topicDir: string): Promise<DownloadProgress> {
    const progress: DownloadProgress = {
      paperId: paper.id,
      title: paper.title || 'Untitled Paper',
      status: 'pending',
      progress: 0,
      storedInDatabase: false,
      contentType: 'application/pdf',
      filePath: null,
      fileSize: 0,
      downloadStrategy: 'none'
    };

    try {
      progress.status = 'downloading';
      const baseFilename = this.generateSafeFilename(paper);
      
    
      if (paper.url && paper.url.includes('arxiv.org')) {
        const pdfSuccess = await this.tryArxivPDF(paper, baseFilename, topicDir, progress);
        if (pdfSuccess) return progress;
      }

      
      if (paper.url && paper.url.includes('semanticscholar.org')) {
        const pdfSuccess = await this.trySemanticScholarPDF(paper, baseFilename, topicDir, progress);
        if (pdfSuccess) return progress;
      }

      
      if (paper.doi) {
        const pdfSuccess = await this.tryDoiPDF(paper, baseFilename, topicDir, progress);
        if (pdfSuccess) return progress;
      }

      
      if (paper.url) {
        const pdfSuccess = await this.tryGenericPDF(paper, baseFilename, topicDir, progress);
        if (pdfSuccess) return progress;
      }

      
      await this.createEnhancedTextFile(paper, baseFilename, topicDir, progress);
      return progress;

    } catch (error) {
      progress.status = 'failed';
      progress.error = error instanceof Error ? error.message : 'Unknown error';
      console.error(`‚ùå All PDF download strategies failed for ${paper.id}:`, error);
      return progress;
    }
  }


  private async tryArxivPDF(paper: any, baseFilename: string, topicDir: string, progress: DownloadProgress): Promise<boolean> {
    try {
      const arxivId = this.extractArxivId(paper.url);
      if (!arxivId) return false;

      const pdfUrl = `https://arxiv.org/pdf/${arxivId}.pdf`;
      const filePath = path.join(topicDir, `${baseFilename}.pdf`);
      
      console.log(`üìÑ Downloading arXiv PDF: ${pdfUrl}`);
      await this.downloadFile(pdfUrl, filePath);
      
      const fileContent = fs.readFileSync(filePath);
      const stats = fs.statSync(filePath);
      
      await neo4jService.updatePaperWithContent(paper.id, fileContent, 'application/pdf');
      await neo4jService.updatePaperLocalFile(paper.id, filePath, stats.size);
      
      progress.status = 'completed';
      progress.progress = 100;
      progress.filePath = filePath;
      progress.fileSize = stats.size;
      progress.storedInDatabase = true;
      progress.downloadStrategy = 'arxiv_pdf';
      
      console.log(`‚úÖ arXiv PDF downloaded: ${paper.id} (${stats.size} bytes)`);
      return true;
      
    } catch (error) {
      console.warn(`‚ö†Ô∏è arXiv PDF failed for ${paper.id}:`, error);
      return false;
    }
  }

  private async trySemanticScholarPDF(paper: any, baseFilename: string, topicDir: string, progress: DownloadProgress): Promise<boolean> {
    try {
      const semanticId = paper.url.split('/').pop();
      const response = await axios.get(`https://api.semanticscholar.org/graph/v1/paper/${semanticId}`, {
        params: { fields: 'openAccessPdf,externalIds' },
        timeout: 8000
      });
      
      let pdfUrl = response.data.openAccessPdf?.url;
      
      // Try alternative PDF sources
      if (!pdfUrl && response.data.externalIds?.ArXiv) {
        pdfUrl = `https://arxiv.org/pdf/${response.data.externalIds.ArXiv}.pdf`;
      }
      
      if (!pdfUrl && response.data.externalIds?.DOI) {
        // Try DOI resolver (commented out sci-hub for legal compliance)
        // pdfUrl = `https://sci-hub.se/${response.data.externalIds.DOI}`;
      }
      
      if (pdfUrl) {
        const filePath = path.join(topicDir, `${baseFilename}.pdf`);
        await this.downloadFile(pdfUrl, filePath);
        
        const fileContent = fs.readFileSync(filePath);
        const stats = fs.statSync(filePath);
        
        await neo4jService.updatePaperWithContent(paper.id, fileContent, 'application/pdf');
        await neo4jService.updatePaperLocalFile(paper.id, filePath, stats.size);
        
        progress.status = 'completed';
        progress.progress = 100;
        progress.filePath = filePath;
        progress.fileSize = stats.size;
        progress.storedInDatabase = true;
        progress.downloadStrategy = 'semantic_scholar_pdf';
        
        console.log(`‚úÖ Semantic Scholar PDF downloaded: ${paper.id} (${stats.size} bytes)`);
        return true;
      }
      
      return false;
      
    } catch (error) {
      console.warn(`‚ö†Ô∏è Semantic Scholar PDF failed for ${paper.id}:`, error);
      return false;
    }
  }


  private async tryDoiPDF(paper: any, baseFilename: string, topicDir: string, progress: DownloadProgress): Promise<boolean> {
    try {
      // Multiple DOI resolution strategies (legal ones only)
      const doiUrls = [
        `https://dx.doi.org/${paper.doi}`,
        `https://doi.org/${paper.doi}`
      ];
      
      for (const doiUrl of doiUrls) {
        try {
          const filePath = path.join(topicDir, `${baseFilename}.pdf`);
          await this.downloadFile(doiUrl, filePath);
          
          // Verify it's actually a PDF
          const buffer = fs.readFileSync(filePath, { encoding: null });
          if (buffer.slice(0, 4).toString() === '%PDF') {
            
            await neo4jService.updatePaperWithContent(paper.id, buffer, 'application/pdf');
            await neo4jService.updatePaperLocalFile(paper.id, filePath, buffer.length);
            
            progress.status = 'completed';
            progress.progress = 100;
            progress.filePath = filePath;
            progress.fileSize = buffer.length;
            progress.storedInDatabase = true;
            progress.downloadStrategy = 'doi_pdf';
            
            console.log(`‚úÖ DOI PDF downloaded: ${paper.id} (${buffer.length} bytes)`);
            return true;
          } else {
            fs.unlinkSync(filePath); // Remove non-PDF file
          }
        } catch (urlError) {
          console.warn(`‚ö†Ô∏è DOI URL failed: ${doiUrl}`, urlError);
          continue;
        }
      }
      
      return false;
      
    } catch (error) {
      console.warn(`‚ö†Ô∏è DOI PDF failed for ${paper.id}:`, error);
      return false;
    }
  }

  //  Try generic URL PDF download
  private async tryGenericPDF(paper: any, baseFilename: string, topicDir: string, progress: DownloadProgress): Promise<boolean> {
    try {
      // Check if URL might be a direct PDF link
      if (paper.url.toLowerCase().includes('.pdf') || 
          paper.url.toLowerCase().includes('pdf')) {
        
        const filePath = path.join(topicDir, `${baseFilename}.pdf`);
        await this.downloadFile(paper.url, filePath);
        
        // Verify it's a PDF
        const buffer = fs.readFileSync(filePath, { encoding: null });
        if (buffer.slice(0, 4).toString() === '%PDF') {
          
          await neo4jService.updatePaperWithContent(paper.id, buffer, 'application/pdf');
          await neo4jService.updatePaperLocalFile(paper.id, filePath, buffer.length);
          
          progress.status = 'completed';
          progress.progress = 100;
          progress.filePath = filePath;
          progress.fileSize = buffer.length;
          progress.storedInDatabase = true;
          progress.downloadStrategy = 'generic_pdf';
          
          console.log(`‚úÖ Generic PDF downloaded: ${paper.id} (${buffer.length} bytes)`);
          return true;
        } else {
          fs.unlinkSync(filePath);
        }
      }
      
      return false;
      
    } catch (error) {
      console.warn(`‚ö†Ô∏è Generic PDF failed for ${paper.id}:`, error);
      return false;
    }
  }

  // üéØ Create enhanced text file (fallback)
  private async createEnhancedTextFile(paper: any, baseFilename: string, topicDir: string, progress: DownloadProgress): Promise<void> {
    const enhancedContent = this.generateEnhancedPaperContent(paper);
    const textFilePath = path.join(topicDir, `${baseFilename}.txt`);
    
    fs.writeFileSync(textFilePath, enhancedContent, 'utf8');
    
    await neo4jService.updatePaperWithContent(paper.id, enhancedContent, 'text/plain');
    await neo4jService.updatePaperLocalFile(paper.id, textFilePath, enhancedContent.length);
    
    const stats = fs.statSync(textFilePath);
    progress.status = 'completed';
    progress.progress = 100;
    progress.filePath = textFilePath;
    progress.fileSize = stats.size;
    progress.storedInDatabase = true;
    progress.downloadStrategy = 'enhanced_text';
    progress.contentType = 'text/plain';
    
    console.log(`‚úÖ Enhanced text created: ${paper.id} (${stats.size} bytes)`);
  }

  //  Helper methods
  private extractArxivId(url: string): string | null {
    const arxivRegex = /(?:arxiv\.org\/(?:abs\/|pdf\/))?([\d]{4}\.[\d]{4,5}(?:v\d+)?)/i;
    const match = url.match(arxivRegex);
    return match ? match[1] : null;
  }

  private generateSafeFilename(paper: any): string {
    const title = paper.title || 'Untitled_Paper';
    const safeName = title
      .replace(/[^a-zA-Z0-9\s\-_]/g, '')
      .replace(/\s+/g, '_')
      .substring(0, 80);
    
    const year = paper.year || new Date().getFullYear();
    const firstAuthor = paper.authors?.[0]?.split(' ').pop() || 'Unknown';
    
    return `${year}_${firstAuthor}_${safeName}`;
  }

  private generateEnhancedPaperContent(paper: any): string {
    const authors = Array.isArray(paper.authors) ? paper.authors.join(', ') : 'Unknown Authors';
    
    return `
# ${paper.title || 'Untitled Paper'}

## Research Paper Metadata
- **Authors**: ${authors}
- **Publication Year**: ${paper.year || 'Unknown'}
- **Venue**: ${paper.venue || 'Unknown Venue'}
- **Citations**: ${paper.citationCount || 0}
- **Paper ID**: ${paper.id}
- **Original URL**: ${paper.url || 'Not available'}
- **DOI**: ${paper.doi || 'Not available'}

## Abstract
${paper.abstract || 'Abstract not available for this paper.'}

## Keywords and Topics
${paper.keywords ? paper.keywords.join(', ') : 'Keywords not specified'}

## Research Context
This paper appears to be related to research in areas involving machine learning, artificial intelligence, and computational sciences based on the content analysis.

## Technical Details
- **Download Method**: Enhanced text extraction (PDF not available)
- **Content Type**: Research paper metadata and abstract
- **Storage**: Full metadata stored in ResearchReasoner database
- **Accessibility**: Full content available through ResearchReasoner platform

## Access Information
- **Downloaded**: ${new Date().toISOString()}
- **Platform**: ResearchReasoner Research Discovery System
- **Database Storage**: Complete metadata and content analysis available
- **Research Integration**: Connected to related papers through citation and content analysis

---

### ResearchReasoner Analysis
This paper has been processed through the ResearchReasoner platform for research discovery and knowledge graph generation. While the full PDF was not accessible, comprehensive metadata and abstract analysis provide substantial research value.

For citation purposes, please refer to the original source using the provided URL or DOI when available.

**Note**: This enhanced text file contains all available information about the research paper. The ResearchReasoner platform has analyzed and stored this content for research discovery and knowledge mapping purposes.
`.trim();
  }

  private async downloadFile(url: string, filePath: string): Promise<void> {
    const response = await axios({
      method: 'GET',
      url: url,
      responseType: 'stream',
      timeout: 30000,
      maxRedirects: 5,
      headers: {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Accept': 'application/pdf,text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.5',
        'Accept-Encoding': 'gzip, deflate',
        'DNT': '1',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1'
      }
    });

    const writer = fs.createWriteStream(filePath);
    await streamPipeline(response.data, writer);
  }

  private getTopicDirectory(paper: any, topic?: string): string {
    if (topic) {
      const safeTopicName = topic.toLowerCase().replace(/\s+/g, '_').replace(/[^a-zA-Z0-9_]/g, '');
      const topicDir = path.join(this.downloadDir, safeTopicName);
      this.ensureDirectoryExists(topicDir);
      return topicDir;
    }
    
    // Auto-detect topic from paper title/abstract
    const text = `${paper.title} ${paper.abstract}`.toLowerCase();
    
    if (text.includes('machine learning') || text.includes('neural network')) {
      return path.join(this.downloadDir, 'machine_learning');
    } else if (text.includes('quantum') || text.includes('physics')) {
      return path.join(this.downloadDir, 'quantum_computing');
    } else if (text.includes('climate') || text.includes('environment')) {
      return path.join(this.downloadDir, 'climate_change');
    }
    
    return path.join(this.downloadDir, 'general');
  }

  //  MISSING METHOD 1: downloadAllPapers (compatible with API calls)
  async downloadAllPapers(papers: any[], topic?: string, storeInDatabase: boolean = true): Promise<BulkDownloadResult> {
    const sessionId = `download_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    
    console.log(`üì• Starting bulk download: ${papers.length} papers (Session: ${sessionId})`);
    if (storeInDatabase) {
      console.log(`üíæ Full content will be stored in Neo4j database`);
    }
    
    const result: BulkDownloadResult = {
      sessionId,
      totalPapers: papers.length,
      completed: 0,
      failed: 0,
      totalSize: 0,
      downloadPaths: [],
      databaseStorageComplete: false,
      pdfDownloaded: 0,
      textCreated: 0,
      progress: papers.map(paper => ({
        paperId: paper.id,
        title: paper.title || 'Untitled Paper',
        status: 'pending',
        progress: 0,
        storedInDatabase: false
      }))
    };

    this.activeDownloads.set(sessionId, result);

    const topicDir = this.getTopicDirectory(papers[0], topic);
    
    // Process downloads in batches to avoid overwhelming servers
    const batches: any[][] = [];
    for (let i = 0; i < papers.length; i += this.maxConcurrentDownloads) {
      batches.push(papers.slice(i, i + this.maxConcurrentDownloads));
    }

    let databaseStorageSuccessCount = 0;

    for (const batch of batches) {
      const downloadPromises = batch.map(async (paper, index) => {
        const paperIndex = papers.indexOf(paper);
        const downloadResult = await this.downloadSinglePaperPDF(paper, topicDir);
        
        // Update progress
        result.progress[paperIndex] = downloadResult;
        
        if (downloadResult.status === 'completed') {
          result.completed++;
          result.totalSize += downloadResult.fileSize || 0;
          
          if (downloadResult.contentType === 'application/pdf') {
            result.pdfDownloaded = (result.pdfDownloaded || 0) + 1;
          } else {
            result.textCreated = (result.textCreated || 0) + 1;
          }
          
          if (downloadResult.filePath) {
            result.downloadPaths.push(downloadResult.filePath);
          }
          if (downloadResult.storedInDatabase) {
            databaseStorageSuccessCount++;
          }
        } else if (downloadResult.status === 'failed') {
          result.failed++;
        }

        console.log(`üìÑ Downloaded ${result.completed}/${papers.length}: ${downloadResult.title} ${downloadResult.storedInDatabase ? '(‚úÖ DB)' : ''}`);
      });

      await Promise.all(downloadPromises);
      
      // Brief pause between batches
      if (batches.indexOf(batch) < batches.length - 1) {
        await new Promise(resolve => setTimeout(resolve, 1000));
      }
    }

    result.databaseStorageComplete = true;

    console.log(`‚úÖ Bulk download complete: ${result.completed} success, ${result.failed} failed`);
    console.log(`üíæ Database storage: ${databaseStorageSuccessCount} papers stored with full content`);
    
    // Clean up session after 1 hour
    setTimeout(() => {
      this.activeDownloads.delete(sessionId);
    }, 3600000);

    return result;
  }

  // ‚úÖ MISSING METHOD 2: getDownloadStats
  getDownloadStats(): any {
    const totalSessions = this.activeDownloads.size;
    
    let totalDownloads = 0;
    let totalSize = 0;
    let totalDatabaseStored = 0;
    
    this.activeDownloads.forEach(session => {
      totalDownloads += session.completed;
      totalSize += session.totalSize;
      totalDatabaseStored += session.progress.filter(p => p.storedInDatabase).length;
    });

    // Get directory size
    const dirSize = this.calculateDirectorySize(this.downloadDir);

    return {
      activeSessions: totalSessions,
      totalDownloadsActive: totalDownloads,
      totalSizeActive: totalSize,
      totalDatabaseStored: totalDatabaseStored,
      databaseStoragePercentage: totalDownloads > 0 ? (totalDatabaseStored / totalDownloads) * 100 : 0,
      downloadDir: this.downloadDir,
      totalDirectorySize: dirSize,
      maxConcurrentDownloads: this.maxConcurrentDownloads
    };
  }

  // ‚úÖ MISSING METHOD 3: getDatabaseStorageStats
  async getDatabaseStorageStats(): Promise<any> {
    try {
      return await neo4jService.getDatabaseStorageStats();
    } catch (error) {
      console.error('‚ùå Error getting database storage stats:', error);
      return {
        connected: false,
        error: 'Failed to get database storage statistics'
      };
    }
  }

  // ‚úÖ MISSING METHOD 4: storeExistingFilesInDatabase
  async storeExistingFilesInDatabase(): Promise<void> {
    console.log(`üì• Storing existing downloaded files in database...`);
    
    try {
      const topicDirs = fs.readdirSync(this.downloadDir).filter(item => {
        const fullPath = path.join(this.downloadDir, item);
        return fs.statSync(fullPath).isDirectory();
      });

      let totalStored = 0;

      for (const topicDir of topicDirs) {
        const topicPath = path.join(this.downloadDir, topicDir);
        const files = fs.readdirSync(topicPath);
        
        console.log(`üìÅ Processing ${files.length} files in ${topicDir}...`);
        
        for (const file of files) {
          const filePath = path.join(topicPath, file);
          const stats = fs.statSync(filePath);
          
          if (stats.isFile()) {
            try {
              // Extract paper ID from filename (basic implementation)
              const paperId = this.extractPaperIdFromFilename(file);
              
              if (paperId) {
                // Read file content
                const fileContent = fs.readFileSync(filePath);
                const contentType = path.extname(filePath) === '.pdf' ? 'application/pdf' : 'text/plain';
                
                // Store in database
                await neo4jService.updatePaperWithContent(paperId, fileContent, contentType);
                totalStored++;
                
                console.log(`‚úÖ Stored ${file} in database (${stats.size} bytes)`);
              }
            } catch (error) {
              console.warn(`‚ö†Ô∏è Failed to store ${file}:`, error);
            }
          }
        }
      }
      
      console.log(`‚úÖ Bulk storage complete: ${totalStored} files stored in database`);
    } catch (error) {
      console.error('‚ùå Error storing existing files:', error);
      throw error;
    }
  }

  //  MISSING METHOD 5: exportDatabaseContent
  async exportDatabaseContent(outputDir: string): Promise<void> {
    console.log(`üì§ Exporting all paper content from database to: ${outputDir}`);
    
    try {
      const papersWithContent = await neo4jService.getPapersWithFullContent();
      
      if (!fs.existsSync(outputDir)) {
        fs.mkdirSync(outputDir, { recursive: true });
      }
      
      for (const paper of papersWithContent) {
        try {
          const fullContent = await neo4jService.getPaperFullContent(paper.id);
          
          if (fullContent.content) {
            const filename = `${paper.id}.${fullContent.contentType === 'application/pdf' ? 'pdf' : 'txt'}`;
            const filePath = path.join(outputDir, filename);
            
            if (Buffer.isBuffer(fullContent.content)) {
              fs.writeFileSync(filePath, fullContent.content);
            } else {
              fs.writeFileSync(filePath, fullContent.content, 'utf8');
            }
            
            console.log(`‚úÖ Exported: ${filename} (${fullContent.originalSize} bytes)`);
          }
        } catch (error) {
          console.warn(`‚ö†Ô∏è Failed to export ${paper.id}:`, error);
        }
      }
      
      console.log(`‚úÖ Export complete: ${papersWithContent.length} papers exported`);
    } catch (error) {
      console.error('‚ùå Error exporting database content:', error);
      throw error;
    }
  }

  // Helper methods
  private extractPaperIdFromFilename(filename: string): string | null {
    // Simple implementation - you might need to adjust based on your naming convention
    const baseName = path.parse(filename).name;
    
    // Try to match with existing papers in database by title similarity
    // This is simplified - return a generated ID or look up in database
    return `paper-${baseName.replace(/[^a-zA-Z0-9]/g, '').toLowerCase()}`;
  }

  private calculateDirectorySize(dirPath: string): number {
    let totalSize = 0;
    
    try {
      const files = fs.readdirSync(dirPath);
      
      for (const file of files) {
        const filePath = path.join(dirPath, file);
        const stats = fs.statSync(filePath);
        
        if (stats.isDirectory()) {
          totalSize += this.calculateDirectorySize(filePath);
        } else {
          totalSize += stats.size;
        }
      }
    } catch (error) {
      console.warn('Error calculating directory size:', error);
    }
    
    return totalSize;
  }

  // üöÄ EXISTING METHOD: downloadAllPapersWithPDFPriority (keep for enhanced calls)
  async downloadAllPapersWithPDFPriority(papers: any[], topic?: string): Promise<any> {
    const sessionId = `pdf_download_${Date.now()}`;
    console.log(`üì• Starting PDF-priority bulk download: ${papers.length} papers`);
    
    const topicDir = this.getTopicDirectory(papers[0], topic);
    const results = {
      sessionId,
      totalPapers: papers.length,
      completed: 0,
      failed: 0,
      totalSize: 0,
      pdfDownloaded: 0,
      textCreated: 0,
      progress: [] as any[],
      downloadPaths: [] as string[]
    };

    // Process in batches to avoid overwhelming servers
    const batches: any[][] = [];
    for (let i = 0; i < papers.length; i += this.maxConcurrentDownloads) {
      batches.push(papers.slice(i, i + this.maxConcurrentDownloads));
    }

    for (const batch of batches) {
      const downloadPromises = batch.map(async (paper) => {
        const downloadResult = await this.downloadSinglePaperPDF(paper, topicDir);
        
        results.progress.push(downloadResult);
        
        if (downloadResult.status === 'completed') {
          results.completed++;
          results.totalSize += downloadResult.fileSize || 0;
          
          if (downloadResult.contentType === 'application/pdf') {
            results.pdfDownloaded++;
          } else {
            results.textCreated++;
          }
          
          if (downloadResult.filePath) {
            results.downloadPaths.push(downloadResult.filePath);
          }
        } else {
          results.failed++;
        }

        console.log(`üìä Progress: ${results.completed}/${papers.length} (PDFs: ${results.pdfDownloaded}, Text: ${results.textCreated})`);
      });

      await Promise.all(downloadPromises);
      
      // Brief pause between batches
      if (batches.indexOf(batch) < batches.length - 1) {
        await new Promise(resolve => setTimeout(resolve, 2000));
      }
    }

    console.log(`‚úÖ PDF-priority download complete!`);
    console.log(`üìÑ PDFs downloaded: ${results.pdfDownloaded}`);
    console.log(`üìù Text files created: ${results.textCreated}`);
    console.log(`üíæ All content stored in database`);
    
    return results;
  }
}